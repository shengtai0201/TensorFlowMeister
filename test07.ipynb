{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "143e787ec9c0edf7f15cb93160417a8c3f9c674469178e2288ca5aba796baeed"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 正則化器\n",
    "# kernel_regularizer 應用於權重\n",
    "# bias_regularizer 應用於偏差單元\n",
    "# activity_regularizer 應用於層激活\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=tf.keras.losses.categorical_crossentropy,metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 11.9134 - categorical_accuracy: 0.1030 - val_loss: 12.2348 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.4632 - categorical_accuracy: 0.1050 - val_loss: 13.0779 - val_categorical_accuracy: 0.0750\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.5959 - categorical_accuracy: 0.1010 - val_loss: 14.5777 - val_categorical_accuracy: 0.0800\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.4239 - categorical_accuracy: 0.1000 - val_loss: 16.8219 - val_categorical_accuracy: 0.0850\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.1237 - categorical_accuracy: 0.1000 - val_loss: 20.0801 - val_categorical_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 21.8591 - categorical_accuracy: 0.1020 - val_loss: 24.1848 - val_categorical_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 25.8964 - categorical_accuracy: 0.1080 - val_loss: 28.0909 - val_categorical_accuracy: 0.1050\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 30.0518 - categorical_accuracy: 0.1040 - val_loss: 32.7529 - val_categorical_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2994 - categorical_accuracy: 0.1040 - val_loss: 39.0873 - val_categorical_accuracy: 0.1050\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.7414 - categorical_accuracy: 0.1060 - val_loss: 47.7953 - val_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237d2662040>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 63.3665 - categorical_accuracy: 0.1135 - val_loss: 81.6824 - val_categorical_accuracy: 0.0833\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 98.5012 - categorical_accuracy: 0.1058 - val_loss: 119.6443 - val_categorical_accuracy: 0.0729\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 136.7587 - categorical_accuracy: 0.1036 - val_loss: 158.5972 - val_categorical_accuracy: 0.1562\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 173.6942 - categorical_accuracy: 0.0983 - val_loss: 192.8783 - val_categorical_accuracy: 0.1458\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 196.7273 - categorical_accuracy: 0.1079 - val_loss: 205.5571 - val_categorical_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 200.6244 - categorical_accuracy: 0.1015 - val_loss: 200.7385 - val_categorical_accuracy: 0.1146\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 195.3488 - categorical_accuracy: 0.1122 - val_loss: 203.8270 - val_categorical_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 209.4131 - categorical_accuracy: 0.1026 - val_loss: 218.9992 - val_categorical_accuracy: 0.1354\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 215.9154 - categorical_accuracy: 0.1090 - val_loss: 219.7987 - val_categorical_accuracy: 0.0729\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 220.3166 - categorical_accuracy: 0.0962 - val_loss: 231.7352 - val_categorical_accuracy: 0.1250\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237d457d430>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30, validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 232.4892 - categorical_accuracy: 0.1040\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 233.7585 - categorical_accuracy: 0.1021\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[233.75845336914062, 0.10208333283662796]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.18728863 0.4559118  0.14430206 ... 0.06930453 0.         0.0266932 ]\n [0.24732514 0.2843916  0.25368527 ... 0.09424144 0.         0.05502426]\n [0.10989207 0.3303275  0.24404441 ... 0.11652344 0.         0.07582325]\n ...\n [0.1363106  0.33968613 0.23164581 ... 0.15476212 0.         0.04521462]\n [0.17738603 0.2545905  0.24966627 ... 0.14506131 0.         0.0648121 ]\n [0.28359172 0.2187151  0.21743731 ... 0.11649952 0.         0.06247961]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}